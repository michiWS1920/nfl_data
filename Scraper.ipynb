{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Scraping** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"feather\")\n",
    "install.packages(\"httr\")\n",
    "install.packages(\"rvest\")\n",
    "install.packages(\"readr\")\n",
    "install.packages(\"tidyr\")\n",
    "install.packages(\"stringr\")\n",
    "install.packages(\"dplyr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rvest)\n",
    "library(readr)\n",
    "library(dplyr)\n",
    "library(httr)\n",
    "library(tidyr)\n",
    "library(stringr)\n",
    "library(feather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create Folders to store data and http caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir.create(\"cache\")\n",
    "\n",
    "dir.create(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following will be the commented scraper code (warning: slow!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html cache function to read the url content \n",
    "\n",
    "read_html_cache <- function(url, cache.dir = 'cache') {\n",
    "  fn <- tail(strsplit(url, '/')[[1]], 1)\n",
    "  fn.path <- paste(cache.dir, fn, sep = '/')\n",
    "  if (!file.exists(fn.path)) {\n",
    "    text <- content(GET(url), as=\"text\")\n",
    "    write(text, fn.path)\n",
    "  }\n",
    "  read_html(fn.path)\n",
    "}\n",
    "\n",
    "# headers of draft and combine dataframes \n",
    "draft.header <- c('round', 'pick', 'team', 'player', 'pos', 'age', 'to', 'ap1', 'pb', 'st', 'carav', 'drav', 'games', \n",
    "                  'pass.cmp', 'pass.att', 'pass.yds', 'pass.tds', 'pass.ints', 'rush.att', 'rush.yds', 'rush.tds', 'receptions', 'rec.yds', 'rec.tds', 'tackles', 'ints', 'sacks', 'college', 'stats')\n",
    "combine.header <- c('player', 'pos', 'college', 'stats', 'height', 'weight', 'forty', 'vertical', 'bench', 'broad',\n",
    "                    'threecone', 'shuttle', 'drafted')\n",
    "\n",
    "url.extract <- function(tds) {\n",
    "  results <- c()\n",
    "  for(td in tds) {\n",
    "    children <- html_children(td)\n",
    "    if (length(children) == 0) {\n",
    "      results <- c(results, NA)\n",
    "    } else{\n",
    "      results <- c(results, (html_attr(html_children(td), 'href')))\n",
    "    }\n",
    "  }\n",
    "  results\n",
    "}\n",
    "\n",
    "# headers of college stats\n",
    "headers <- list()\n",
    "headers[['defense']] <- c('year', 'school', 'conf', 'class', 'pos', 'games', 'solo.tackes', 'ast.tackles', 'tackles', 'loss.tackles', 'sacks', 'int', 'int.yards', 'int.yards.avg', 'int.td', 'pd', 'fum.rec', 'fum.yds', 'fum.tds', 'fum.forced')\n",
    "headers[['scoring']] <- c('year', 'school', 'conf', 'class', 'pos', 'games', 'td.rush', 'td.rec', 'td.int', 'td.fr', 'td.pr', 'td.kr', 'td.oth', 'td.tot', 'kick.xpm', 'kick.fgm', 'twopm', 'safety', 'total.pts')\n",
    "headers[['punt_ret']] <- c('year', 'school', 'conf', 'class', 'pos', 'games', 'punt.returns', 'punt.return.yards', 'punt.return.avg', 'punt.return.td', 'kick.returns', 'kick.return.yards', 'kick.return.avg', 'kick.return.td')\n",
    "headers[['receiving']] <- c('year', 'school', 'conf', 'class', 'pos', 'games', 'receptions', 'rec.yards', 'rec.avg', 'rec.td', 'rush.att', 'rush.yds', 'rush.avg', 'rush.td', 'scrim.plays', 'scrim.yds', 'scrim.avg', 'scrim.tds')\n",
    "headers[['rushing']] <- c('year', 'school', 'conf', 'class', 'pos', 'games', 'receptions', 'rec.yards', 'rec.avg', 'rec.td', 'rush.att', 'rush.yds', 'rush.avg', 'rush.td', 'scrim.plays', 'scrim.yds', 'scrim.avg', 'scrim.tds')\n",
    "headers[['passing']] <- c('year', 'school', 'conf', 'class', 'pos', 'games', 'completions', 'attempts', 'comp.pct', 'pass.yards', 'yards.per.attempt', 'adj.yards.per.attempt', 'pass.tds', 'pass.ints', 'int.rate')\n",
    "\n",
    "parse_pfr_tables <- function(tables) {\n",
    "  results = list()\n",
    "  for (tbl in tables) {\n",
    "    id <- html_attr(tbl, 'id')\n",
    "    if (id %in% names(headers)) {\n",
    "      \n",
    "      df <- html_table(tbl) %>%\n",
    "        head(-1) %>% tail(-1)\n",
    "      \n",
    "      if(ncol(df) == length(headers[[id]])) {\n",
    "        colnames(df) <- headers[[id]]\n",
    "      } else {\n",
    "        next;\n",
    "      }\n",
    "      \n",
    "      melted <- df %>%\n",
    "        select(-year, -school, -conf, -class, -pos) %>%\n",
    "        mutate(seasons = 1) %>%\n",
    "        gather(stat, value) %>%\n",
    "        mutate(stat = as.character(stat)) %>%\n",
    "        filter(value != '') %>%\n",
    "        mutate(value = as.numeric(value),\n",
    "               section = id)\n",
    "      \n",
    "      \n",
    "      results[[id]] <- melted\n",
    "    }\n",
    "  }\n",
    "  bind_rows(results)\n",
    "}\n",
    "\n",
    "# create draft table \n",
    "\n",
    "if (!file.exists('data/drafts.feather')) {\n",
    "  \n",
    "  draft.table <- data_frame(year = 2000:2020) %>%\n",
    "    group_by(year) %>% do({\n",
    "      url <- paste('http://www.pro-football-reference.com/years/', .$year, '/draft.htm', sep ='')\n",
    "      doc <- read_html(url)\n",
    "      html.table <- doc %>%\n",
    "        html_nodes('table') %>%\n",
    "        first\n",
    "      urls <- html.table %>%\n",
    "        html_nodes('tr td:nth-child(29)') %>%\n",
    "        url.extract\n",
    "      my.table <- html_table(html.table)\n",
    "      colnames(my.table) <- draft.header\n",
    "      my.table <- my.table %>%\n",
    "        filter(pos != 'Pos') %>%\n",
    "        mutate(url = urls)\n",
    "      my.table\n",
    "    }) %>%\n",
    "    ungroup\n",
    "  write_feather(draft.table, 'data/drafts.feather')\n",
    "  \n",
    "}\n",
    "\n",
    "# create combine df \n",
    "if (!file.exists('data/combines.feather')) {\n",
    "  \n",
    "  combine.table <- data_frame(year = 2000:2020) %>%\n",
    "    group_by(year) %>% do({\n",
    "      url <- paste('http://www.pro-football-reference.com/draft/', .$year, '-combine.htm', sep ='')\n",
    "      html.table <- read_html(url) %>%\n",
    "        html_nodes('table') %>%\n",
    "        first\n",
    "      urls <- html.table %>%\n",
    "        html_nodes('tr td:nth-child(4)') %>%\n",
    "        url.extract\n",
    "      my.table <- html_table(html.table)\n",
    "      colnames(my.table) <- combine.header\n",
    "      my.table <- my.table %>%\n",
    "        filter(pos != 'Pos') %>%\n",
    "        mutate(url = urls)\n",
    "      my.table\n",
    "    }) %>%\n",
    "    ungroup\n",
    "    \n",
    "# write combine.table in feather format\n",
    "  write_feather(combine.table, 'data/combines.feather')\n",
    "}\n",
    "\n",
    "# all college.stats urls from combine and draft dataframes\n",
    "all.urls <- combine.table %>%\n",
    "  select(url) %>%\n",
    "  full_join(draft.table %>% select(url)) %>%\n",
    "  filter(!is.na(url))\n",
    "\n",
    "# create college.stats df \n",
    "college.stats <- all.urls %>%\n",
    "  group_by(url) %>% do({\n",
    "    doc <- read_html_cache(.$url)\n",
    "    stats <- doc %>%\n",
    "      html_nodes('table') %>%\n",
    "      parse_pfr_tables\n",
    "    if (nrow(stats) > 0) {\n",
    "      stats <- stats %>%\n",
    "        group_by(section, stat) %>%\n",
    "        summarise(value = sum(value))\n",
    "    }\n",
    "    stats\n",
    "  })\n",
    "# write college stats in feather format\n",
    "write_feather(college.stats, 'data/college_stats.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>51008</li><li>4</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 51008\n",
       "\\item 4\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 51008\n",
       "2. 4\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 51008     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(college.stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of the scraper is saved at "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
